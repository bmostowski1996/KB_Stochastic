{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9185dc4",
   "metadata": {},
   "source": [
    "# PDF Crossings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbf2c91",
   "metadata": {},
   "source": [
    "In the work of Glasserman and Pirjol, the shape of the IV curve can be characterized by the number of crossings between the lognormal PDF and the stock price PDF. Here, I will try and build code which can efficiently count the number of such crossings. I will start simple, with just a version suitable for Glasserman and Pirjol before generalizing it to our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8b04441",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "import dependencies as dp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b16621b",
   "metadata": {},
   "source": [
    "## Gaussian Mixture Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a1a703",
   "metadata": {},
   "source": [
    "The parameterization here is inspired by the work of Glasserman and Pirjol and requires a bit of explanation. If $n=1$, then instead of a Gaussian Mixture, we are actually just dealing with a regular Gaussian random variable, whose mean is $ln(m) - 0.5v^2$ and whose variance is $v$. \n",
    "\n",
    "Why would we want to set our parameters in a such a weird way? Let's call this Gaussian random variable $X$ and then define $Y = exp(X)$. For $Z$ standard normal, we then have $$Y = m*exp(vZ - 0.5v^2)$$ Thinking of $Y$ as representing price of a stock sometime in the near future, the parameter $m$ represents the mean price, and $v$ represents the log volatility --- that is, it represents the volatility of the logarithm of the price.\n",
    "\n",
    "So, when $n=1$, $X$ is a log-price random variable with mean $log(m) - 0.5v^2$ and volatility $v$. If $n > 1$, now $X$ is a *mixture* of log-prices and the best interpretation of $Y$ is that $Y$ is the exponential of of these log-prices.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e1f4f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: [0.25 0.5  0.25]\n",
      "Mean Prices: [0.79600998 0.8824969  1.19401498]\n",
      "Volatilities: [0.1 0.5 0.1]\n"
     ]
    }
   ],
   "source": [
    "m = np.array([0.8,1,1.2])\n",
    "#v = np.exp(-1.6 + 0.7*norm.rvs(size=n_comp))\n",
    "v = np.array([0.1,0.5,0.1])\n",
    "o = 0.50\n",
    "w = np.array([(1-o)/2, o, (1-o)/2])\n",
    "\n",
    "means = np.array(np.log(m) - 0.5*(v**2))\n",
    "volatilities = v\n",
    "weights = w\n",
    "\n",
    "print(\"Weights: \" + str(weights))\n",
    "print(\"Mean Prices: \" + str(np.exp(means)))\n",
    "print(\"Volatilities: \" + str(volatilities))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcc8547",
   "metadata": {},
   "source": [
    "Our goal here is now to measure the number of crossings between the PDF of price and the PDF of a lognormal random variable with the same expectation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746fd6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hGMpdf()\n",
    "    #Find the pdf of the "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
